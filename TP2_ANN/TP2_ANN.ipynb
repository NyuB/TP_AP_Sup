{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 : Multi-Layer Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Echantillonage du jeu de données et séparation en entraînement/test\n",
    "*NB* : Au vu des temps d'exécution constatés, nous nous sommes limité à 1/10 du jeu de données initial, soit 7000 images au lieu des 70000 demandées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose sample size\n",
    "dataset_length = len(mnist.data)\n",
    "sample_size = 7000\n",
    "sample_size = min(dataset_length,sample_size)\n",
    "\n",
    "#extract sample from dataset\n",
    "sample_indexes = np.random.randint(dataset_length, size= sample_size)\n",
    "data, target = np.array([mnist.data[i] for i in sample_indexes]), np.array([mnist.target[i] for i in sample_indexes])\n",
    "\n",
    "#extract train/test according to the proportion given in the subject\n",
    "train_size = 49000/70000 #keep the given proportion\n",
    "d_train, d_test, l_train, l_test = train_test_split(data,target,train_size = train_size, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Premiers réseaux de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construire un modèle de classification ayant comme paramètre :hidden_layer_sizes = (50) puis calculez la précision du classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8728571428571429\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50), random_state=42)\n",
    "mlp.fit(d_train, l_train)\n",
    "score = mlp.score(d_test, l_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Afficher la classe de l’image 4 et sa classe prédite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction : 1\n",
      "actual : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test de prediction = valeur réel \n",
    "img_index = 3 #4th image of the dataset\n",
    "images = data.reshape((-1, 28, 28)) \n",
    "plt.imshow(images[img_index],cmap=plt.cm.gray_r,interpolation=\"nearest\") \n",
    "res = mlp.predict(data[img_index:img_index+1])[0]\n",
    "print(\"prediction :\",res)\n",
    "print(\"actual :\",target[img_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculez la précision en utilisant le package : metrics.precision_score(ytest_pr, ypredTest_pr,average='micro')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8728571428571429\n"
     ]
    }
   ],
   "source": [
    "res = mlp.predict(d_test)\n",
    "precision = metrics.precision_score(l_test,\n",
    "                                    res, \n",
    "                                    average='micro')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Analyse : Nombres de couches et neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Varier le nombre de couches de 1 entre (2 et 100) couches, et recalculer la précision du classifieur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for 2 7.285797834396362 s\n"
     ]
    }
   ],
   "source": [
    "best_layers_nb = 0\n",
    "layers_nb_set = [2,5,15,20,25,35,45,55,65]\n",
    "best_score = 0\n",
    "plot = ([],[],[])\n",
    "\n",
    "neurons = np.geomspace(80, 40, num=100, dtype=int)#reduce neuron number gradually to ensure convergence\n",
    "\n",
    "start = time() #TIMER START\n",
    "for layers_nb in layers_nb_set:\n",
    "    start_iter = time()\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=neurons[:layers_nb])\n",
    "    mlp.fit(d_train, l_train)\n",
    "    prediction = mlp.predict(d_test)\n",
    "    score = metrics.precision_score(l_test, prediction, average='micro')\n",
    "    duration_iter = time()-start\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_layers_nb = layers_nb\n",
    "    plot[0].append(layers_nb)\n",
    "    plot[1].append(score)\n",
    "    plot[2].append(duration_iter)\n",
    "    print(\"Execution time for\",layers_nb,duration_iter,\"s\")\n",
    "    \n",
    "duration = time()-start #TIMER END\n",
    "\n",
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(111, label=\"precision\")\n",
    "ax2=ax.twinx()\n",
    "\n",
    "ax.set_xlabel(\"n layers\")\n",
    "ax.set_ylabel(\"precision (%)\")\n",
    "ax.set_title(\"Precision et temps d'exécution en fonction du nombre de couches utilisées\")\n",
    "ax.plot(plot[0],plot[1])\n",
    "ax.plot([best_layers_nb],[best_score], marker= 'x', color='r')\n",
    "\n",
    "ax2.set_ylabel(\"temps (s)\")\n",
    "ax2.plot(plot[0],plot[2],color='r')\n",
    "\n",
    "print(\"Optimal layers number :\",best_layers_nb, \"( score :\",best_score,\")\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interprétation\n",
    "On observe que la précision augmente graduellement puis chute rapidement lorsque l'on dépasse 25 couches.\n",
    "\n",
    "Puisque le temps d'exécution augmente lui fortement avec le nombre de couches, il semble préférable de se limiter à moins d'une vingtaine de couches pour notre analyse, voire moins d'une sizaine pusique là différence en précision est très faible.\n",
    "\n",
    "On notera cependant que le nombre de neurones par couche joue probablement un rôle déterminant dans cette évolution, d'où la nécessité de l'analyse suivante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construire cinq modèles de classification des données mnist avec des réseaux qui ont respectivement de 1 à 10 couches cachées, et des tailles de couches entre 10 et 300 neurones au choix d’une façon aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_random_models(n,layers_nb_range, layers_size_range):\n",
    "    layers_nb = np.random.randint(low = layers_nb_range[0],high = layers_nb_range[1], size = n)\n",
    "    layers_sizes = np.random.randint(low = layers_size_range[0],high = layers_size_range[1], size = n)\n",
    "    res = []\n",
    "    for i in range(n):\n",
    "        nb = layers_nb[i]\n",
    "        size = layers_sizes[i]\n",
    "        model = MLPClassifier(hidden_layer_sizes=[size for j in range(nb)])\n",
    "        res.append((model, nb, size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = build_random_models(5,(1,11),(10,301))\n",
    "results = []\n",
    "for model, nb, size in models:\n",
    "    start = time()\n",
    "    model.fit(d_train, l_train)\n",
    "    prediction = model.predict(d_test)\n",
    "    score = metrics.precision_score(l_test, prediction, average='micro')\n",
    "    duration = time()-start\n",
    "    print(\"Executed\",nb,size,\"score :\",score,\"in\",duration,\"second\")\n",
    "    results.append((score,nb,size,duration))\n",
    "results = sorted(results)\n",
    "for score, nb, size, duration in result:\n",
    "    print(\"Layers :\",nb,\"Neurons :\",size,\"Precision :\",score*100,\"%\",\"Exec :\",duration,\"s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interprétation\n",
    "La précision du modèle augmente avec le nombre de couches(comme vu précedemment) mais surtout avec le nombre de neurones par couche. Etendre ce nombre de neurones représente cependant un coût en temps. Pour une itération, nous avons obtenu un modèle optimal à 94% de précision, avec 10 couches et 251 neurones par courche mais dont l'entraînement + prédiction prenait plus d'une minute sur 7000 données.\n",
    "\n",
    "Un bon compromis semble être trouvé avec un modèle une cinquantaine de neurones sur 8 couches, soit 300 neurones au total, qui obtient un score > 90% pour 20 sec de temps d'exécution total.\n",
    "\n",
    "Par la suite, on conservera ce nombre de 8 couches et 300 neurones comme référence.\n",
    "En revanche, on répartira les neurones de façon moins uniforme entre les couches, par exemple en utilisant np.geomspace pour obtenir une répartition logarithmique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] Analyse des paramètres supplémentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common parameters for the rest of the analysis\n",
    "layers_nb = 6\n",
    "layers_size = 50\n",
    "\n",
    "up_size = 1.25 * layers_size\n",
    "down_size = 0.75*layers_size\n",
    "\n",
    "neurons = np.geomspace(up_size, down_size, num=layers_nb, dtype=int)#reduce neuron number gradually to ensure convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithmes d'optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_set = ['lbfgs', 'sgd', 'adam']\n",
    "plot = ([],[],[],[],[])\n",
    "for algo in algo_set:\n",
    "    print(\"Algo :\",algo)\n",
    "    start = time()#TIMER START\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=neurons, solver = algo)\n",
    "    mlp.fit(d_train, l_train)\n",
    "    prediction = mlp.predict(d_test)\n",
    "    \n",
    "    duration = time() - start #TIMER END\n",
    "    \n",
    "    recall = metrics.recall_score(l_test, prediction, average = 'micro')\n",
    "    score = metrics.precision_score(l_test, prediction, average='micro')\n",
    "    error = metrics.zero_one_loss(l_test, prediction)\n",
    "    \n",
    "    plot[0].append(algo)\n",
    "    plot[1].append(score)\n",
    "    plot[2].append(recall)\n",
    "    plot[3].append(error)\n",
    "    plot[4].append(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "ax1=fig.add_subplot(111, label=\"precision\")\n",
    "ax2=ax1.twinx()\n",
    "ax3=ax2.twinx()\n",
    "ax4=ax3.twinx()\n",
    "\n",
    "ax1.plot(plot[0],plot[1],linestyle='None',marker='o',color='r')\n",
    "ax1.set_ylabel(\"Precision (%)\")\n",
    "ax2.plot(plot[0],plot[2],linestyle='None',marker='o',color='b')\n",
    "ax2.set_ylabel(\"Recall (%)\")\n",
    "ax3.plot(plot[0],plot[3],linestyle='None',marker='o',color='g')\n",
    "ax3.set_ylabel(\"Error\")\n",
    "ax4.plot(plot[0],plot[4],linestyle='None',marker='X',color='r')\n",
    "ax4.set_ylabel(\"Execution(s)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctions d'activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_set = ['identity', 'logistic', 'tanh', 'relu']\n",
    "plot = ([],[],[],[],[])\n",
    "for function in function_set:\n",
    "    print(\"Function :\",function)\n",
    "    start = time()#TIMER START\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=neurons, activation = function)\n",
    "    mlp.fit(d_train, l_train)\n",
    "    prediction = mlp.predict(d_test)\n",
    "    \n",
    "    duration = time() - start #TIMER END\n",
    "    \n",
    "    recall = metrics.recall_score(l_test, prediction, average = 'micro')\n",
    "    score = metrics.precision_score(l_test, prediction, average='micro')\n",
    "    error = metrics.zero_one_loss(l_test, prediction)\n",
    "    \n",
    "    plot[0].append(function)\n",
    "    plot[1].append(100*score)\n",
    "    plot[2].append(100*recall)\n",
    "    plot[3].append(error)\n",
    "    plot[4].append(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "ax1=fig.add_subplot(111, label=\"precision\")\n",
    "ax2=ax1.twinx()\n",
    "ax3=ax2.twinx()\n",
    "ax4=ax3.twinx()\n",
    "\n",
    "ax1.plot(plot[0],plot[1],linestyle='None',marker='o',color='r')\n",
    "ax1.set_ylabel(\"Precision (%)\")\n",
    "ax2.plot(plot[0],plot[2],linestyle='None',marker='o',color='b')\n",
    "ax2.set_ylabel(\"Recall (%)\")\n",
    "ax3.plot(plot[0],plot[3],linestyle='None',marker='o',color='g')\n",
    "ax3.set_ylabel(\"Error\")\n",
    "ax4.plot(plot[0],plot[4],linestyle='None',marker='X',color='r')\n",
    "ax4.set_ylabel(\"Execution(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régulation L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_set = [10**(-i) for i in range(8,0,-1)]\n",
    "plot = ([],[],[],[],[])\n",
    "for alpha in alpha_set:\n",
    "    print(\"Regulation L2 :\",alpha)\n",
    "    start = time()#TIMER START\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=neurons, alpha = alpha)\n",
    "    mlp.fit(d_train, l_train)\n",
    "    prediction = mlp.predict(d_test)\n",
    "    \n",
    "    duration = time() - start #TIMER END\n",
    "    \n",
    "    recall = metrics.recall_score(l_test, prediction, average = 'micro')\n",
    "    score = metrics.precision_score(l_test, prediction, average='micro')\n",
    "    error = metrics.zero_one_loss(l_test, prediction)\n",
    "    \n",
    "    plot[0].append(alpha)\n",
    "    plot[1].append(100*score)\n",
    "    plot[2].append(100*recall)\n",
    "    plot[3].append(error)\n",
    "    plot[4].append(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "ax1=fig.add_subplot(111, label=\"precision\")\n",
    "ax2=ax1.twinx()\n",
    "ax3=ax2.twinx()\n",
    "ax4=ax3.twinx()\n",
    "\n",
    "ax1.plot(plot[0],plot[1],linestyle='None',marker='o',color='r')\n",
    "ax1.set_ylabel(\"Precision (%)\")\n",
    "ax2.plot(plot[0],plot[2],linestyle='None',marker='o',color='b')\n",
    "ax2.set_ylabel(\"Recall (%)\")\n",
    "ax3.plot(plot[0],plot[3],linestyle='None',marker='o',color='g')\n",
    "ax3.set_ylabel(\"Error\")\n",
    "ax4.plot(plot[0],plot[4],linestyle='None',marker='X',color='r')\n",
    "ax4.set_ylabel(\"Execution(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIN TP2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
