{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 : Exploration du jeu de données\n",
    "### 1.1 Inspection de la structure du jeu de données\n",
    "\n",
    "On analyse la nature et les dimensions des données à notre disposition. Le rôle et la valeur attendue est indiquée en commentaire pour chaque propriété"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1\n",
    "print(mnist) #représentation des paramètres du jeu de données, les images, leurs labels,\n",
    "#et des informations supplémentaires de numpy (9 champs en tout)\n",
    "\n",
    "print (mnist.data) #les images(chiffres) du dataset\n",
    "print (mnist.target) #les labels(chiffre représenté par l'image) du dataset, 1 pour chaque image\n",
    "print (len(mnist.data)) #le nombre d'images du dataset\n",
    "print (mnist.data.shape) #la dimension des images du dataset (70000 * 784)\n",
    "print (mnist.target.shape) #la dimension des labels du dataset (70000 * 1)\n",
    "print (mnist.data[0]) #la première image du dataset\n",
    "print (mnist.data[0][1]) #le deuxième pixel de la première image du dataset\n",
    "print (mnist.data[:,1]) #le deuxième pixel de chaque image du dataset\n",
    "print (mnist.data[:100]) #les 100 premières images du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Affichage d'une image et du label associé\n",
    "Plot d'une image : Puisque les images du dataset sont 'écrasées' en une dimension de 784 pixel, on les redimensionne d'abord au format ligne/colonne 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index = 0\n",
    "images = mnist.data.reshape((-1, 28, 28))\n",
    "plt.imshow(images[img_index],cmap=plt.cm.gray_r,interpolation=\"nearest\")\n",
    "print(\"Associated label :\",mnist.target[img_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Extraction de données aléatoires\n",
    "Enfin, on utilise les fonctions numpy pour extraire un échantillon aléatoire depuis le jeu de donénes initial, qui servira pour la suite du TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose sample size\n",
    "dataset_length = len(mnist.data)\n",
    "sample_size = 5000\n",
    "sample_size = min(dataset_length,sample_size)\n",
    "\n",
    "#extract sample from dataset\n",
    "sample_indexes = np.random.randint(dataset_length, size= sample_size)\n",
    "data, target = np.array([mnist.data[i] for i in sample_indexes]), np.array([mnist.target[i] for i in sample_indexes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Méthode KNN\n",
    "### 2.1 Premières classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diviser la base de données à 80% pour l’apprentissage (training) et à 20% pour les tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "d_train, d_test, l_train, l_test = train_test_split(data,target,train_size = train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrainer un classifieur k-nn avec k = 10 sur le jeu de données chargé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(10)\n",
    "clf.fit(d_train,l_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Afficher la classe de l’image 4 et sa classe prédite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_index = 3\n",
    "prediction = clf.predict(([data[pred_index]]))[0] #predict method awaits a list of data\n",
    "expected = target[pred_index]\n",
    "print(prediction, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Afficher le score sur l’échantillon de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.score(d_test, l_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quel est le taux d'erreur sur vos données d'apprentissage ? Est-ce normal ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.score(d_train, l_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient un taux d'erreur non-nul (score < 100%)\n",
    "C'était à attendre, puisque le modèle ne n'ajuste pas pour vérifier chaque échantillon du jeu de test, seulement un maximum d'entre eux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faire varier le nombre de voisins (k) de 2 jusqu’à 15 et afficher le score. \n",
    "#### Quel est le k optimal ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "best_nb = 0 #k optimal\n",
    "train_size = 0.8\n",
    "d_train, d_test, l_train, l_test = train_test_split(data,target,train_size = train_size)\n",
    "n_nb_set = range(2,16)\n",
    "plot=([],[])\n",
    "\n",
    "start = time() #TIMER START\n",
    "\n",
    "for n_nb in n_nb_set:\n",
    "    #print(\"Computing for\",n_nb,train_size)\n",
    "    clf = KNeighborsClassifier(n_nb)\n",
    "    clf.fit(d_train\t,l_train)\n",
    "    score = clf.score(d_test, l_test)\n",
    "    #print(\"Score :\",score)\n",
    "    if score>best_score:\n",
    "        best_nb = n_nb\n",
    "        best_score = score\n",
    "    plot[0].append(n_nb)\n",
    "    plot[1].append(score)\n",
    "    \n",
    "duration = time() - start #TIMER END\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_xlabel(\"k neighbours\")\n",
    "ax.set_ylabel(\"score (%)\")\n",
    "ax.set_title(\"Score en fonction du nombre de voisins pris en compte\")\n",
    "ax.plot(plot[0],plot[1])\n",
    "ax.plot([best_nb],[best_score], marker= 'x', color='r')\n",
    "\n",
    "print(\"Optimal k :\", best_nb, \"( score :\",best_score,')')\n",
    "print(\"Executed in\",duration,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre de voisins(k) optimal semble être 5. Ce sera donc la valeur retenue pour les prochains tests où l'on devra fixer ce paramètre.\n",
    "\n",
    "On notera cependant que les scores obtenus sont très proches, et semblent plus stable autour de 9 voisins.\n",
    "On observe une dgradation globale pour des valeurs supérieures à 9 voisins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faites varier le pourcentage des échantillons (training et test) et affichez le score. \n",
    "#### Quel est le pourcentage remarquable ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0 \n",
    "best_size = 0 #training sample size\n",
    "train_size_set = [i*0.05 for i in range(6,17)] #variation between 30-80 by 5% steps\n",
    "n_nb = 5 #from previous estimations\n",
    "plot=([],[])\n",
    "\n",
    "start = time() #TIMER START\n",
    "clf = KNeighborsClassifier(n_nb)\n",
    "for train_size in train_size_set:\n",
    "    d_train, d_test, l_train, l_test = train_test_split(data,target,train_size = train_size)\n",
    "    clf.fit(d_train\t,l_train)\n",
    "    score = clf.score(d_test, l_test)\n",
    "    if score>best_score:\n",
    "        best_score = score\n",
    "        best_size = train_size\n",
    "    plot[0].append(100*train_size)\n",
    "    plot[1].append(score)\n",
    "    \n",
    "duration = time() - start #TIMER END\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_xlabel(\"training size (%)\")\n",
    "ax.set_ylabel(\"score (%)\")\n",
    "ax.set_title(\"Score en fonction de la proportion de l'échantillon d'entraînement/test pour k = 5\")\n",
    "ax.plot(plot[0],plot[1])\n",
    "\n",
    "print(\"Optimal training proportion :\",best_size, \"( score :\",best_score,')')\n",
    "print(\"Executed in\",duration,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe une croissance nette du score jusqu'à 65% du dataset utilisé pour l'entraînement, puis une chute jusqu'à 70%\n",
    "Le score croit ensuite de nouveau passé 70%, mais le pourcentage de données alors utilisées pour le test perd en signification : si l'on prenait 99% de données d'entraînement, le score serait probablement idéal mais le modèle serait moins pertinent une fois appliqué sur d'autres données.\n",
    "Un bon compromis efficacité/pertinence semble donc être 65% d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faites varier les types de distances (p). \n",
    "#### Quelle est la meilleure distance ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dist = 0\n",
    "best_score = 0\n",
    "dist_set = [1,2,3]\n",
    "train_size = 0.65 #from previous tests\n",
    "n_nb = 5 #from previous tests\n",
    "d_train, d_test, l_train, l_test = train_test_split(data,target,train_size = train_size)\n",
    "plot=([],[])\n",
    "\n",
    "start = time() #TIMER START\n",
    "\n",
    "for dist in dist_set:\n",
    "    start_iter = time()\n",
    "    clf = KNeighborsClassifier(n_nb, p = dist)\n",
    "    clf.fit(d_train\t,l_train)\n",
    "    score = clf.score(d_test, l_test)\n",
    "    duration_iter = time()-start_iter\n",
    "    print(\"Execution for metric\",dist,\":\",duration_iter,\"s\")\n",
    "    if score>best_score:\n",
    "        best_score = score\n",
    "        best_dist = dist\n",
    "    plot[0].append(dist)\n",
    "    plot[1].append(score)\n",
    "    \n",
    "duration = time() - start #TIMER END\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.set_xlabel(\"minkowski metric (p)\")\n",
    "ax.set_ylabel(\"score (%)\")\n",
    "ax.set_title(\"Score en fonction de la proportion de la distance utilisée (1 = mahnattan, 2 = euclid)\")\n",
    "ax.plot(plot[0],plot[1])\n",
    "print(\"Optimal distance :\",best_dist, \"( score :\",best_score,')')\n",
    "print(\"Executed in\",duration,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La métrique de distance optimale semble donc être obtenue pour la distance de minkowski 4, et la tendance semble croissante avec la métrique utilisée.\n",
    "En revanche, les temps d'exécution explose (x10) lorsque l'on sort des deux métriques classiques manhattan et euclidienne (1 et 2 respectivement). La métrique pertinente semble donc être la distance euclidienne, compromis en efficacité et rapidité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixez n_job à 1 puis à -1 et calculez le temps de chacun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.65 #from previous tests\n",
    "n_nb = 5 #from previous tests\n",
    "dist = 2\n",
    "d_train, d_test, l_train, l_test = train_test_split(data,target,train_size = train_size)\n",
    "\n",
    "\n",
    "clfA = KNeighborsClassifier(n_nb, p = dist, n_jobs = 1)\n",
    "clfB = KNeighborsClassifier(n_nb, p = dist, n_jobs = -1)\n",
    "\n",
    "start = time()\n",
    "clfA.fit(d_train, l_train)\n",
    "score = clf.score(d_test, l_test)\n",
    "duration = time() - start\n",
    "print(\"Execution for n_jobs = 1:\",duration,\"s\")\n",
    "\n",
    "start = time()\n",
    "clfB.fit(d_train, l_train)\n",
    "score = clf.score(d_test, l_test)\n",
    "duration = time() - start\n",
    "print(\"Execution for n_jobs = -1:\",duration,\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A votre avis, quels sont les avantages et les inconvénients des k-nn : \n",
    "#### optimalité ? temps de calcul ? passage à l'échelle ?\n",
    "\n",
    "Les k-nn sont efficaces  /!\\ A compléter /!\\\n",
    "\n",
    "En revanche, il est nécessaire de définir un jeu d'entraînement suffisamment petit et néanmoins représentatif. En effet, plus le jeu d'entraînement sera grand, plus le nombre de mesure de distance à effectuer pour une prédiction sera élevé.\n",
    "\n",
    "De plus, la définition de la métrique de distance est cruciale et doit également être un compromis pertinence/temps de calcul car elle seraexécutée de nombreuse fois et représente la quasi totalité de la complexité de l'algorithme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIN TP 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
